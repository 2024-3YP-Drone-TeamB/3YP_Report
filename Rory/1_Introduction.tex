\subsection{Introduction and Objectives} \label{compvis_intro}

     \noindent The computer vision system is responsible for converting sensor data into intelligent predictions of landmine locations, while being robust to variations in landmines and environmental conditions. The effectiveness of this component determines the overall systemâ€™s ability to save lives and restore land to productive use. The design and performance of the computer vision system are considered in this section. 
     
    \subsubsection{Key Objectives}
    
        \noindent The primary objective of the computer vision system is to accurately detect landmines using the available multi-modal sensor data. The system is designed to detect landmines with high system recall $R_{sys}$ (defined as the fraction of landmines correctly predicted), and moderately high system precision $P_{sys}$ (defined as the fraction of predictions that were correct), across a wide range of environmental conditions, while balancing system performance with operational autonomy and overall cost. Given the greater cost associated with false negatives (labelling a mined region as safe) compared to false positives (labelling a safe region as mined), the system is designed to prioritize recall over precision. This aspect is discussed further in Section \ref{lossmatrix}.

    \subsubsection{Literature Review and Design Decisions} 
    
        Deep learning-based solutions for computer vision and data fusion are advocated for in recent literature, as deep learning (DL) can demonstrate superior performance in managing high-dimensional, noisy data \cite{Li2023Robust}. Barnawi et al. \cite{barnawi2022review} recommend \textit{"developing an automated deep learning based solution that integrates several technologies relevant to imaging and automation"} for landmine detection, highlighting that deep learning is the state of the art in both inference, and sensor fusion. Alqudsi et al. \cite{alqudsi2021review} recommend \textit{"developing an integrated detection system ... with the assist of ground sensors to achieve better detection and mapping results"}, which indicates that \textbf{environmental contextual data can improve the fused detection results}.
    
    \paragraph{Computer Vision} 

        Both the thermal and radar sensor data can be represented as images (Section \ref{sensor_overview}). The problem of computer vision is the accurate detection of landmine signatures within these complex images. The current state-of-the-art in object detection is the You Only Look Once (YOLO\footnote{\url{https://github.com/ultralytics/ultralytics}}) architecture from Ultralytics, which is a family of architectures based on convolutional neural networks (CNNs). YOLO is suitable for detecting landmine signatures in images, due to its ability to do computationally efficient, robust, and high-performance inference in images that are potentially occluded or obscured by a cluttered environment.
    
    \paragraph{Sensor Fusion} 
    
        \noindent Several works in literature (for example, \cite{qui2023fusion}) propose an early/mid stage fusion approach. The approach taken in Section \ref{fusion} is late stage, deep learning fusion. Late stage fusion facilitates the addition of environmental contextual data, as recommended by Alqudsi et al. The justification for the specific implementation of the fusion algorithm, and how contextual data is implemented, is in Section \ref{fusion}. The fusion strategy is justified on the basis that it yields more reliable results on diverse environmental conditions under-represented in the training data. The fusion method makes use of the environmental contextual data by \textbf{constraining the fusion weights to be 'physically plausible'}.
    


