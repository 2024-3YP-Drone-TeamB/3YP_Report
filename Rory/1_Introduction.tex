\subsection{Introduction and Objectives} \label{compvis_intro}

     \noindent The computer vision system is responsible for converting sensor data into intelligent predictions of landmine locations, while being robust to variations in landmines and environmental conditions. The effectiveness of this component directly determines the overall systemâ€™s ability to save lives and restore land to productive use. The design and performance of the computer vision system are considered in this section. 
     
    \subsubsection{Key Objectives}
    
        \noindent The primary objective of the computer vision system is to accurately detect landmines using the available multi-modal sensor data. The system is designed to detect landmines with high system recall $R_{sys}$, and moderately high system precision $P_{sys}$, across a wide range of environmental conditions, while balancing system performance with operational autonomy and overall cost. Given the greater cost associated with false negatives (labelling a mined region as safe) compared to false positives (labelling a safe region as mined), the system is designed to prioritize recall over precision. This aspect is discussed further in Section \ref{lossmatrix}.

    \subsubsection{Literature Review and Design Decisions} 
    
        Deep learning-based solutions for computer vision and data fusion are endorsed in recent literature, as they demonstrate superior performance in managing high-dimensional, noisy data. Barnawi et al. \cite{barnawi2022review} recommend \textit{"developing an automated deep learning based solution that integrates several technologies relevant to imaging and automation"}, highlighting that deep learning is the state of the art in both inference, and sensor fusion. Alqudsi et al. \cite{alqudsi2021review} recommend \textit{"developing an integrated detection system ... with the assist of ground sensors to achieve better detection and mapping results"}, which indicates that environmental contextual data can improve the fused detection results.
    
    \paragraph{Computer Vision} 

        \noindent As described in Section \ref{hardware}, the data from the thermal and radar sensors are both images. The problem of computer vision is accurately detecting landmine signatures within these complex images. The current state of the art in object detection is the You Only Look Once (YOLO\footnote{\url{https://github.com/ultralytics/ultralytics}}) architecture, which is an architecture based on convolutional neural networks (CNNs). YOLO's ability to do computationally efficient, robust, and high performance inference makes it suitable for detecting landmine signatures that are often partially occluded or obscured by a cluttered environment.
    
    \paragraph{Sensor Fusion} 
    
        \noindent Several works in literature (for example, \cite{qui2023fusion}) propose an early/mid stage fusion approach. The approach taken in Section \ref{fusion} is late stage, deep learning fusion. Late stage fusion facilitates the addition of environmental contextual data, as recommended by Alqudsi. The justification for the specific implementation of the fusion algorithm, and how contextual data is implemented, is in Section \ref{fusion}. The fusion strategy is justified on the basis that it yields more reliable results across diverse environmental conditions, by being constrained to 'physically plausible' fusion weights.
    


